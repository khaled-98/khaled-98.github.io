---
layout: post
title:  "Monte Carlo Localisation (MCL) - Part 1: Bayesian Estimation"
date:   2021-01-09 21:00:00 +0000
categories: robotics localisation
math: true
---
_Note: This post is work in progress._

In this series of posts, I'll be explaining the Monte Carlo Localisation algorithm, its components and some of its variants through interactive demos.
{:style="text-align: justify;"}

This particular post will introduce the localisation problem briefly and how bayesian estimation can be used to solve it.

# The Localisation Problem

In order for a robot to know where it is in an environment that lacks a global positioning system (e.g. indoors where GPS is not available), it must rely on its sensors to localise itself. However, most sensors suffer from errors that can build over time, for example inertial sensors drift over time and encoders can build up errors when wheels slip.
{:style="text-align: justify;"}

As a result of these problems, an effective localisation algorithm must be able to correct for these errors. One way to achieve this, is by thinking about the position of the robot probabilisticly rather than deterministically. This means modelling the position of the robot using a probability distribution that reflects the uncertainty introduced by sensing errors. This probability distribution can be updated over time to incorporate new data as it becomes available. Enter Bayesian Estimation!
{:style="text-align: justify;"}

# Bayesian Estimation

I will not go into the detail of how Bayes Theorem works here because others have done a much better job at explaining it than I can - I recommend [3Blue1Brown's](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) video, embedded below. Instead I'll focus on how the theorem can be used for robot localisation.
{:style="text-align: justify;"}

<center style="margin:50px">
    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/HZGCoVF3YvM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

Put simply, Bayes Theorem, shown below, describes the probability of an event (A) occurring, given our prior knowledge about the event (B). 
{:style="text-align: justify;"}

$$
\begin{equation}
    p(A|B) = \frac{p(B|A) \cdot p(A)}{p(B)}
    \label{eq:bayes}
\end{equation}
$$

The same theorem can also be used to express the probability of an event (A) occurring, given multiple other events (B and C):

$$p(A|B,C) = \frac{p(B|A,C) \cdot p(A|C)}{p(B|C)}$$

In the context of robot localisation events A, B and C can be defined as follows:

* **A**: The location of the robot at time $t$, $x_t$.
* **B**: A series of sensor readings observed by the robot up to time $t$, $z_{1:t}$.
* **C**: A series of actions taken by the robot up to time $t$, $u_{1:t}$.

$$p(x_t|z_{1:t},u_{1:t}) = \frac{p(z_{1:t}|x_t,u_{1:t}) \cdot p(x_t|u_{1:t})}{p(z_{1:t}|u_{1:t})} = \frac{p(z_t|x_t,z_{1:t-1},u_{1:t}) \cdot p(x_t|z_{1:t-1},u_{1:t})}{p(z_t|z_{1:t-1}, u_{1:t})} = bel(x_t)$$

> See appendix at the end of the page for the derivation of the above equation.

In other words, this is the probability that the robot is at location $x$ at time $t$ given all the actions it took and all the observations it made up to time $t$. This is known as the robot's _belief_ about $x$ at time $t$, which can also be denoted as $bel(x_t)$. This relationship is really powerful because it provides us with a way of estimating the robot's belief (i.e. where it thinks it is), based on its actions (e.g. how it moved) and what it "saw" through its sensors.
{:style="text-align: justify;"}

Ideally we want to update this belief iteratively: as the robot takes new actions and obtains new sensor readings, it updates its belief. However, the formula in its current form doesn't really allow us to do that, so we will have to simplify it using some assumptions and probability laws.
{:style="text-align: justify;"}

The first assumption we will make is that if the robot's current state is known then we don't need to know its previous states in order to be able to estimate its future states. For example, if we know where the robot is at this point in time, what action it took and what sensor observation it made then we can estimate where it is going to end up next without knowing where it was before.
{:style="text-align: justify;"}

> Formally, this is know as the [Markov assumption](https://en.wikipedia.org/wiki/Markov_property). Strictly speaking, we can't really fully define the current state of the robot. For that we would have to know precisely where the robot is, where every obstacle (including unmodelled obstacles such as a passing human) is and many other things, which is not practical. However, in practice, probablistic algorithms are quite robust to these discrepancies.
{:style="text-align: justify;"}

Articulating this assumption into maths, we can simplify $p(z_t|x_t,z_{1:t-1},u_{1:t})$ into $p(z_t|x_t)$, because we assume that what the robot is currently observing, $z_t$, is only affected by its current state, $x_t$:

$$bel(x_t) = \eta \cdot p(z_t|x_t) \cdot p(x_t|z_{1:t-1},u_{1:t})$$

Using the law of total probability we get:

$$bel(x_t) = \eta \cdot p(z_t|x_t) \cdot \int p(x_t|x_{t-1},u_t) \cdot p(x_{t-1}|z_{1:t-1},u_{1:t}) dx_{t-1}$$


{% include bayes_localisation.html %}

___

# Appendix

bla bla